{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import os\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up parameters\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "BATCH_SIZE = 16\n",
    "train_dir = r'../../data-train-val-test-one-folder\\train'\n",
    "validation_dir = r'../../data-train-val-test-one-folder/val'\n",
    "test_dir = r'../../data-train-val-test-one-folder/test'\n",
    "excelPathTrain = r'../../excel/multi-view/csv/multi-view-train.csv'\n",
    "excelPathVal = r'../../excel/multi-view/csv/multi-view-val.csv'\n",
    "excelPathTest = r'../../excel/multi-view/csv/multi-view-test.csv'\n",
    "root = r'../../data'\n",
    "epochs = 5\n",
    "modelSavePath = r'../../models/multi-view'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiGenDF(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, view_generators, shuffle):\n",
    "        self.view_generators = view_generators\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = view_generators[0].batch_size\n",
    "        self.num_steps = len(view_generators[0])\n",
    "        self.indices = np.arange(view_generators[0].samples)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        data = []\n",
    "        for gen in self.view_generators:\n",
    "            minibatch = gen._get_batches_of_transformed_samples(indices)\n",
    "            data.append(minibatch[0])\n",
    "        labels = minibatch[1]\n",
    "        return data, labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_steps\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetClassesAndParts(root):\n",
    "    classes = os.listdir(root) # gets a list of all classes from data\n",
    "    pathToParts = os.path.join(root, classes[0])\n",
    "    parts = os.listdir(pathToParts) # gets a list of all parts from data\n",
    "    return classes, parts\n",
    "\n",
    "def rescale_2_minus_1_and_1(img):\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    img = (img - 0.5) * 2\n",
    "    return img\n",
    "\n",
    "            \n",
    "def build_datagenerator_df(df, input_size, batch_size, views, shuffle, dir, train_val = True, seed=0):\n",
    "    \n",
    "    if train_val:\n",
    "        generator = ImageDataGenerator(width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            zoom_range=0.2,\n",
    "                            fill_mode='nearest',\n",
    "                            horizontal_flip = True,\n",
    "                            preprocessing_function=rescale_2_minus_1_and_1)\n",
    "    \n",
    "    else:\n",
    "        generator = ImageDataGenerator(preprocessing_function=rescale_2_minus_1_and_1)\n",
    "\n",
    "    view_generators = []\n",
    "\n",
    "    for view in views:\n",
    "        view_generators.append(\n",
    "            generator.flow_from_dataframe(\n",
    "                dataframe=df,\n",
    "                directory=dir,\n",
    "                x_col=view,\n",
    "                y_col='class',\n",
    "                target_size=input_size,\n",
    "                class_mode='categorical',\n",
    "                shuffle=False,\n",
    "                seed = seed,\n",
    "                batch_size=batch_size   \n",
    "            )\n",
    "        )\n",
    "\n",
    "    return MultiGenDF(view_generators=view_generators, shuffle=shuffle)\n",
    "\n",
    "def buildLateFusionFC(models):\n",
    "\n",
    "    inputs = [keras.layers.Input(shape=(256,256,3)) for i in range(len(models))]\n",
    "\n",
    "    streams = []\n",
    "    i = 0\n",
    "    for model in models:\n",
    "        temp = keras.Model(model.input, model.layers[-2].output)\n",
    "        temp.layers[-1]._outbound_nodes = []\n",
    "        temp.trainable = False\n",
    "        streams.append(temp(inputs[i]))\n",
    "        i += 1\n",
    "\n",
    "    fusionFC = keras.layers.Concatenate()(streams)\n",
    "\n",
    "    fusionFC = keras.layers.Dense(model[0].layers[-1].get_config()['units'], activation='softmax')(fusionFC)\n",
    "\n",
    "    multi_view = keras.Model(inputs, fusionFC)\n",
    "\n",
    "    return multi_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, parts = SetClassesAndParts(root)\n",
    "\n",
    "train_data_multi = pd.read_csv(excelPathTrain)\n",
    "multi_gen_df_train = build_datagenerator_df(train_data_multi, (256,256), BATCH_SIZE//3, views=parts, shuffle = True, dir=train_dir)\n",
    "\n",
    "validation_data_multi = pd.read_csv(excelPathVal)\n",
    "multi_gen_df_validation = build_datagenerator_df(validation_data_multi, (256,256), BATCH_SIZE//3, views=parts, shuffle = True, dir=validation_dir)\n",
    "\n",
    "test_data_multi = pd.read_csv(excelPathTest)\n",
    "multi_gen_df_test = build_datagenerator_df(test_data_multi, batch_size=BATCH_SIZE, shuffle = False, input_size=(256,256), views=parts, dir=test_dir, train_val=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for part in parts: # FIX: How to choose the best model for each view, not sure yet so is using fixed number and model\n",
    "    models.append(keras.models.load_model(os.path.join(\"models\\single-view\", part, part + \"_model_2.h5\")))\n",
    "multi_view = buildLateFusionFC(models)\n",
    "multi_view.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(multi_view, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(os.path.join(modelSavePath, \"multi-view.h5\"), \n",
    "\t\t\t\t\t\t\tmonitor='val_loss', verbose=1, \n",
    "\t\t\t\t\t\t\tsave_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001),\n",
    "                      EarlyStopping(monitor= \"val_loss\", patience=5),\n",
    "                      checkpoint]\n",
    "optimizer = Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_view.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "multi_view.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = multi_view.fit(\n",
    "        multi_gen_df_train,\n",
    "        epochs=epochs,\n",
    "        verbose = 1,\n",
    "        validation_data=multi_gen_df_validation,\n",
    "        callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_view.evaluate(multi_gen_df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
